{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1726405846649,
     "user": {
      "displayName": "Ben",
      "userId": "11632414893030619302"
     },
     "user_tz": -60
    },
    "id": "k8fgOEPByabj"
   },
   "outputs": [],
   "source": [
    "#Import necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "import seaborn as sns\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3W8E4kryabu"
   },
   "source": [
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1726405804063,
     "user": {
      "displayName": "Ben",
      "userId": "11632414893030619302"
     },
     "user_tz": -60
    },
    "id": "ofQGBwsIyabx",
    "outputId": "6a2d28be-9a2c-4ab7-93d9-60498777f59e"
   },
   "outputs": [],
   "source": [
    "#Load Image path\n",
    "import os\n",
    "img_path = os.listdir(r\"training\")\n",
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1726407677657,
     "user": {
      "displayName": "Ben",
      "userId": "11632414893030619302"
     },
     "user_tz": -60
    },
    "id": "Z1Ay38qO0hab"
   },
   "outputs": [],
   "source": [
    "helper_function_file_path = 'helper_func.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 482,
     "status": "ok",
     "timestamp": 1726407679501,
     "user": {
      "displayName": "Ben",
      "userId": "11632414893030619302"
     },
     "user_tz": -60
    },
    "id": "FtPns1fO1TaG"
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"helper_func\", helper_function_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1726407681721,
     "user": {
      "displayName": "Ben",
      "userId": "11632414893030619302"
     },
     "user_tz": -60
    },
    "id": "EUNkUDDR2ZQS"
   },
   "outputs": [],
   "source": [
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "error",
     "timestamp": 1726408094313,
     "user": {
      "displayName": "Ben",
      "userId": "11632414893030619302"
     },
     "user_tz": -60
    },
    "id": "3HSZ2nYwyab2",
    "outputId": "7ec2d5e3-9107-4e7d-f2ca-1ef9b2c618c0"
   },
   "outputs": [],
   "source": [
    "#Generate Train Images and train labels\n",
    "import helper_func as hf\n",
    "\n",
    "train_images, train_labels = hf.generate_dataset(r\"training/*\",128)\n",
    "#Generate test image and test labels\n",
    "test_images, test_labels = hf.generate_dataset(r\"testing/*\", 128)\n",
    "\n",
    "#Generate validationimage and validation labels\n",
    "valid_images, valid_labels = hf.generate_dataset(r\"validation/*\",128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkz5fASayab4",
    "outputId": "aac5fb50-cecf-4e11-fd93-9767e6be003d"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PWEGp_7yab5"
   },
   "source": [
    "##### Encode labels from text to integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNtCMWgXyab7"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Combine all labels\n",
    "all_labels = np.concatenate([train_labels, test_labels, valid_labels])\n",
    "le = LabelEncoder()\n",
    "# Fit the LabelEncoder\n",
    "le.fit(all_labels)\n",
    "\n",
    "# Encode training, test, and validation labels\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "validation_labels_encoded = le.transform(valid_labels)\n",
    "\n",
    "print(train_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNQBO-A6yab9",
    "outputId": "c09b982d-ab26-41bf-a2ad-657a47580bda"
   },
   "outputs": [],
   "source": [
    "train_labels_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sczYeRpyyab_"
   },
   "source": [
    "##### Split data into test and train dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "is2TZJo9yacA",
    "outputId": "640b66be-e94f-4e01-fbdf-6c78fb630af8"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "x_valid, y_valid = valid_images, validation_labels_encoded\n",
    "\n",
    "#Check for imbalance in target class\n",
    "pd.DataFrame(train_labels).value_counts()\n",
    "\n",
    "# fig, axes = plt.subplots(1,1, figsize=(8,6))\n",
    "# axes.set_title('Bargraph for classes')\n",
    "# plot = sns.countplot(x=test_labels, saturation=2, ax=axes)\n",
    "# plot.patches[0].set_facecolor('orange')\n",
    "# plot.patches[1].set_facecolor('purple')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Check for imbalance in target class\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize=(8,6)) # <-- UNCOMMENTED\n",
    "axes.set_title('Bargraph for classes')       # <-- UNCOMMENTED\n",
    "plot = sns.countplot(x=test_labels, saturation=2, ax=axes) # <-- UNCOMMENTED\n",
    "\n",
    "colors = ['orange', 'purple', 'green', 'blue', 'red']\n",
    "\n",
    "for i, patch in enumerate(plot.patches):\n",
    "    # Only try to apply a color if the patch index is within the length of your 'colors' list\n",
    "    if i < len(colors):\n",
    "        patch.set_facecolor(colors[i])\n",
    "    else:\n",
    "        # Use a default color for classes beyond your pre-defined list\n",
    "        patch.set_facecolor('gray') \n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKHqHTDRyacC"
   },
   "source": [
    "##### Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrr_joIkyacF"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to between 0 and 1\n",
    "# By dividing x_train and x_test by 255.0\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_valid = x_valid / 255.0\n",
    "\n",
    "# Normalize y_train and y_test\n",
    "#One hot encode y values for neural network.\n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzILrgKQyacG"
   },
   "source": [
    "##### Feature extraction from images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHTS_PATH = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "# print(WEIGHTS_PATH)\n",
    "\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4MezEOxyacH",
    "outputId": "669171fc-8b90-4155-d2af-08a11bd15c55"
   },
   "outputs": [],
   "source": [
    "# Load model wothout classifier/fully connected layers\n",
    "SIZE = 128\n",
    "# VGG_model = VGG16(weights=WEIGHTS_PATH, include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "# VGG_model = ResNet50(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "# VGG_model.summary()  #Trainable parameters will be 0\n",
    "\n",
    "##Extract features from x_train\n",
    "#Now, let us use features from convolutional network\n",
    "feature_extractor=VGG_model.predict(x_train)\n",
    "\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "##Store the extracted features in a new X_train variable to be used to train models\n",
    "X_train = features\n",
    "\n",
    "#This is our X input to train Model\n",
    "\n",
    "#Extract features from test images using VGG16\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature = VGG_model.predict(x_test)\n",
    "#store extracted features in a variable X_test that will be used for model prediction\n",
    "X_test = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
    "\n",
    "#Extract features from validation images\n",
    "#Send validation data through same feature extractor process\n",
    "X_valid_feature = VGG_model.predict(x_valid)\n",
    "#store extracted features in a variable X_valid that will be used for model validation\n",
    "X_valid = X_valid_feature.reshape(X_valid_feature.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdQ-yNBjyacI"
   },
   "source": [
    "### Train Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r4ehNCztyacJ"
   },
   "outputs": [],
   "source": [
    "# import helper function to evaluate model performance\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import evaluation2 as eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3CCd9ZYyacK"
   },
   "source": [
    "### Random Forest Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozUQFOgqyacL",
    "outputId": "e0828a3b-3420-465a-c2e8-bdaff5dbe410"
   },
   "outputs": [],
   "source": [
    "#Train RANDOM FOREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier(n_estimators = 50, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K31kjz8pyacN"
   },
   "outputs": [],
   "source": [
    "rf_train_time = eval.measure_training_time(RF_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvyOF3otyacN"
   },
   "outputs": [],
   "source": [
    "#Now predict using the trained RF model.\n",
    "# prediction_RF = RF_model.predict(X_test)\n",
    "prediction_RF = RF_model.predict(X_test)\n",
    "\n",
    "#Inverse le transform to get original label back.\n",
    "\n",
    "#Inverse le transform to get original label back.\n",
    "prediction_RF_text = le.inverse_transform(prediction_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgNOOaD-yacO"
   },
   "source": [
    "### SVM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKd00apeyacO",
    "outputId": "f7c6fd92-654f-40dc-e7fd-78f5fe679304"
   },
   "outputs": [],
   "source": [
    "# Train Support Vector Machine model\n",
    "from sklearn.svm import SVC\n",
    "# Train SVM model\n",
    "SVM_model = SVC(probability=True)\n",
    "SVM_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-LgLzCdyacP"
   },
   "outputs": [],
   "source": [
    "svm_train_time = eval.measure_training_time(SVM_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vX0GdPvQyacP"
   },
   "outputs": [],
   "source": [
    "# SVM model Prediction\n",
    "SVM_pred = SVM_model.predict(X_test)\n",
    "SVM_pred_text = le.inverse_transform(SVM_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kobIxzEjyacQ"
   },
   "source": [
    "### Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VwMN83s2yacQ",
    "outputId": "e72a1245-083a-4354-ac56-6e64f54b287a"
   },
   "outputs": [],
   "source": [
    "#Train Naive Bayes Model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_Model = GaussianNB(var_smoothing=1e-07)\n",
    "NB_Model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNgCxObpyacR"
   },
   "outputs": [],
   "source": [
    "NB_train_time = eval.measure_training_time(NB_Model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meJxiEnOyacS"
   },
   "outputs": [],
   "source": [
    "# Naive bayes model Prediction\n",
    "NB_pred = NB_Model.predict(X_test)\n",
    "NB_pred_text = le.inverse_transform(NB_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIPJL6GvyacS"
   },
   "source": [
    "#### Linear Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dl9sOK3nyacT"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a logistic regression model\n",
    "LR_Model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "LR_Model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "LR_pred = LR_Model.predict(X_test)\n",
    "LR_pred_text = le.inverse_transform(LR_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ik_yB1rHyacT"
   },
   "source": [
    "### Models Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2F7z9AcuyacU"
   },
   "source": [
    "##### Random forest report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEqrRm-iyacV"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "72xbLJlQyacV",
    "outputId": "4080b232-7c08-464c-f92e-05d86f8adba5"
   },
   "outputs": [],
   "source": [
    "# classification report random forest\n",
    "eval.report(test_labels,prediction_RF_text, \"Random forest\")\n",
    "#AUC ROC for random forest\n",
    "eval.plot_auc_roc_curve(RF_model, \"Random forest\", X_test, y_test)\n",
    "# Confusion matrix random forest\n",
    "eval.plot_confusion_matrix(test_labels, prediction_RF_text, \"Random forest\")\n",
    "\n",
    "# Specificity for random forest\n",
    "rf_specificity = eval.specificity(y_test,prediction_RF)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xZqrzYuyacX"
   },
   "source": [
    "##### Support vector machine report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um5CkUuzyacY",
    "outputId": "aac357db-bfa3-4e3c-fde4-9c505dccead2"
   },
   "outputs": [],
   "source": [
    "# classification report random forest\n",
    "eval.report(test_labels,SVM_pred_text, \"Support Vector Machine\")\n",
    "#AUC ROC for random forest\n",
    "eval.plot_auc_roc_curve(RF_model, \"Support vector Machine\", X_test, y_test)\n",
    "# Confusion matrix random forest\n",
    "eval.plot_confusion_matrix(test_labels, SVM_pred_text, \"Support Vector Machine\")\n",
    "\n",
    "# Specificity for random forest\n",
    "svm_specificity = eval.specificity(y_test,prediction_RF)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ipy5QkPyacZ"
   },
   "source": [
    "#### LR Evaluation Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryP9-EYAyaca",
    "outputId": "329a43c6-8f39-440a-96f1-038fa01769c9"
   },
   "outputs": [],
   "source": [
    "# classification report random forest\n",
    "eval.report(test_labels,LR_pred_text, \"Linear Regression\")\n",
    "#AUC ROC for random forest\n",
    "eval.plot_auc_roc_curve(LR_Model, \"Linear Regression\", X_test, y_test)\n",
    "# Confusion matrix random forest\n",
    "eval.plot_confusion_matrix(test_labels,LR_pred_text, \"Linear Regression\")\n",
    "\n",
    "\n",
    "\n",
    "# Specificity for random forest\n",
    "LR_specificity = eval.specificity(y_test,LR_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQNFsWFlyacc"
   },
   "source": [
    "### Comparative Analysis of models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpVniXIKyacp"
   },
   "source": [
    "##### Model metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBfi8MIDyacq"
   },
   "outputs": [],
   "source": [
    "#Accuracy score for models\n",
    "rf_accuracy,svm_accuracy,LR_accuracy = eval.model_accuracy(y_test,prediction_RF,SVM_pred,LR_pred)\n",
    "#Precision score for the models\n",
    "rf_precision,svm_precision,LR_precision = eval.model_precision(y_test,prediction_RF,SVM_pred,LR_pred)\n",
    "#Sensitivity score for the models\n",
    "rf_recall,svm_recall,LR_recall = eval.model_recall(y_test,prediction_RF,SVM_pred,LR_pred)\n",
    "#F1_score for the models\n",
    "rf_score,svm_score,LR_score = eval.model_f1_score(y_test,prediction_RF,SVM_pred,LR_pred)\n",
    "#Specificity\n",
    "rf_specificity = eval.specificity(y_test, prediction_RF)*100\n",
    "svm_specificity = eval.specificity(y_test, SVM_pred)*100\n",
    "LR_specificity = eval.specificity(y_test, LR_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "do2L_tiayacr"
   },
   "outputs": [],
   "source": [
    "# Classification report for all models\n",
    "models = {\"Random forest\": prediction_RF, \"SVM\": SVM_pred, \"Linear Regression\": LR_pred}\n",
    "performance_metrics = {\n",
    "    \"Accuracy\": (rf_accuracy, svm_accuracy, LR_accuracy),\n",
    "    \"Precision\": (rf_precision, svm_precision, LR_precision),\n",
    "    \"Sensitivity\": (rf_recall, svm_recall, LR_recall),\n",
    "    \"Specificity\": (rf_specificity, svm_specificity, LR_specificity),\n",
    "    \"F1_score\": (rf_score, svm_score, LR_score)\n",
    "}\n",
    "\n",
    "model_train_time = (rf_train_time, svm_train_time, NB_train_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiPiHyMTyacs"
   },
   "source": [
    "#### Classification report for all models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvqGfyLSyact",
    "outputId": "54c6eabc-d20f-45b8-ff19-7f65cc49b23d"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "df_report = pd.DataFrame()\n",
    "df_report = df_report.transpose()\n",
    "\n",
    "\n",
    "df_report.index = models.keys()\n",
    "# Add accuracy scores to the table\n",
    "df_report['Accuracy'] = performance_metrics[\"Accuracy\"]\n",
    "# Add specificity scores to the table\n",
    "df_report['Specificity'] = performance_metrics[\"Specificity\"]\n",
    "# Add precision scores to the table\n",
    "df_report['Precision'] = performance_metrics[\"Precision\"]\n",
    "# Add recall scores to the table\n",
    "df_report['Sensitivity'] = performance_metrics[\"Sensitivity\"]\n",
    "# Add f1_score scores to the table\n",
    "df_report['f1_score'] = performance_metrics[\"F1_score\"]\n",
    "# Add model train time to the table\n",
    "df_report['CPU_wall_time (ms)'] = model_train_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert values to percentages\n",
    "df_report = df_report.map(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "\n",
    "# Display the table\n",
    "print('Model Metrics')\n",
    "print(tabulate(df_report, headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7d1ePGfyacv"
   },
   "source": [
    "##### stacked Bar chart showing the performance for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTwQuBM7yacw",
    "outputId": "5a792542-74e5-4915-85a7-dcad431e9096"
   },
   "outputs": [],
   "source": [
    "eval.sbar_chart(models.keys(), performance_metrics)\n",
    "#ROC_AUC_CURVE\n",
    "# Generate predictions\n",
    "\n",
    "y_pred_proba_rf = RF_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_proba_svm = SVM_model.predict_proba(X_test)[:,1]\n",
    "y_pred_proba_lr = LR_Model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "test_df = pd.DataFrame({'True': y_test,'RandomForest': y_pred_proba_rf, 'SVM': y_pred_proba_svm, 'Linear Regression': y_pred_proba_lr})\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot ROC curve for each model\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "for model in ['RandomForest', 'SVM', \"Linear Regression\"]:\n",
    "  fpr, tpr, _ = roc_curve(test_df['True'], test_df[model])\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "  plt.plot(fpr, tpr, label=f'{model} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# Plot random guess line\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Guess')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Three Models')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVXZfF98yacx"
   },
   "source": [
    "#### Save models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_t2LF_Oyacy",
    "outputId": "ba275fba-c8e2-4b63-8519-9c0f7ed13fd0"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(RF_model,\"RF_CLF.model\")\n",
    "dump(SVM_model,\"SVM_CLF.model\")\n",
    "dump(LR_Model,\"LR_CLF.model\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
